---
title: "Prediction Assignment Writeup"
author: "O.S."
date: "16 November 2018"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Executive Summary 
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible
to collect a large amount of data about personal activity relatively inexpensively.
The purpose of this exercise is to use the data to try and 
predict five type of activities (the way they did the training)


Libraries 
```{r }
library(ggplot2)
library(caret)
library(gbm)
library(parallel)
library(doParallel)
library(dplyr)
library(rpart)
library(rpart.plot)

```

## Load Data
Loading the data.

```{r load data, }
training = read.csv("E:/Elements/Coursera/Data Sciense/Course 8 - Practical Machine Learning/Project/pml-training.csv")

validiation = read.csv("E:/Elements/Coursera/Data Sciense/Course 8 - Practical Machine Learning/Project/pml-testing.csv")

```

### Data observation
```{r}
dim(training)
```
The training dataset contains 19622 observations and 160 variables.

```{r}
dim(validiation)
```
The validation set is 20 observations over 160 variables. 

## Data cleaning
Calculate the NA percentage.

```{r}
NAnoTrain<-sum(is.na(training))
NAtrainPercentage<-NAnoTrain/(ncol(training)*nrow(training)) 
NAnoValidiation<-sum(is.na(validiation))
NAValidiationPercentage<-NAnoValidiation/(ncol(validiation)*nrow(validiation)) 
print(NAtrainPercentage)
print(NAValidiationPercentage)



```
t can be sen there is a large number of NA values. 
In the Training set,0.41 of the data is NA.
In the Validation set, 0.625 of the information is NA.

The approach is to check if a column contains more the 80% NA
either in training or in the validation set 
and remove it from both sets (if true).

```{r}

#Calculate the percentage of the NA in each column 
#and remove the columns which 
#have more than 80% NA - Training
TrainColNAPrec<-training %>% 
   summarise_all(funs(100*mean(is.na(.))))
TrainColToRemove<-names(TrainColNAPrec[,TrainColNAPrec>80])


#Calculate the percentage of the NA in each column 
#and remove the columns which 
#have more than 80% NA - Validation
ValidiationColNAPrec<-validiation %>% 
   summarise_all(funs(100*mean(is.na(.))))
ValidiationToRemove<-names(ValidiationColNAPrec[,ValidiationColNAPrec>80])

#Bind the column's names (If the NA percentage is above 80% in 
#one of the set remove the columns from both sets
ColToRemove<-unique(c(TrainColToRemove,ValidiationToRemove))
ColToKeep<-!(names(training) %in% ColToRemove)
Training<-training[ ,ColToKeep]
Validiation<-validiation[ ,ColToKeep]
   
```

Remove the names data and the timestamps related columns
As they will not contribute to the prediction.

```{r}
trainRemove <- grepl("^X|timestamp|window", names(Training))
Training <- Training[, !trainRemove]

ValidiationRemove <- grepl("^X|timestamp|window", names(Validiation))
Validiation <- Validiation[, !ValidiationRemove]
print(dim(Training))
print(dim(Validiation))

```
There are 54 columns left for the Training and Validation. 
 

## Modeling 
The model that will be tested are :

GBM -  (Gradient Boosting Machine) (Boosting with Trees).
RF - Random Forests.

Split the Training set into train and test sets. 
```{r}
set.seed(123444) # For reproducibile purpose
inTrain <- createDataPartition(Training$classe, p=0.70, list=F)
trainData <- Training[inTrain, ]
testData <- Training[-inTrain, ]
```


##GBM Model
```{r}

#Use parallel processing to train the model.
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv",
                           number = 5,
                           allowParallel = TRUE)
```

Train the model. 
```{r }
set.seed(13444)
gbmfit <- train(as.factor(classe)~., method="gbm",data=trainData,trControl = fitControl,verbose = FALSE)
```

Stop parallel processing.
```{r}
stopCluster(cluster)
registerDoSEQ()
```
Predict using the test data to calculate the accuracy.
```{r}
gbmpred <- predict(gbmfit,testData)
gbmaccuracy <- confusionMatrix(gbmpred,testData$classe)$overall['Accuracy']

```

##RF Model
```{r}

#Use parallel processing to train the model.
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv",
                           number = 5,
                           allowParallel = TRUE)
```

Train the model.
```{r}
set.seed(13444)
RFfit <- train(as.factor(classe)~., method="rf",data=trainData,trControl = fitControl)
```
Stop parallel processing.
```{r}
stopCluster(cluster)
registerDoSEQ()
```
Predict using the test data to calculate the accuracy.
```{r}
RFpred <- predict(RFfit,testData)
RFaccuracy <- confusionMatrix(RFpred,testData$classe)$overall['Accuracy']

```
Results:
```{r}
cat("GBM Accuercy:",gbmaccuracy)
cat("RF Accuercy:",RFaccuracy)


```
The Random Forest model provides the best accuracy on the test set 
Here are the model parameters.
```{r}
RFfit
```

Predict (Validation) using the Random Forest model.
```{r}
predict(RFfit,newdata = Validiation)
```


## Appendix
Table of the 20 most important variables in the random forest model.

```{r}
varImp(RFfit)
```

Visualizing the decision tree. 
```{r}
treeModel <- rpart(classe ~ ., data=trainData, method="class")
prp(treeModel) # fast plot
```

